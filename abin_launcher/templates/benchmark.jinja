{# Job instructions for compiling data about the job for benchmarking. -#}
echo -e "\n===================================================================="
echo -e "=====================   Benchmarking Section   ====================="
echo -e "===================================================================="

####################################
#    Benchmarking configuration    #
####################################

# Define the name of the directory where the benchmark CSV files will be created

benchmark_path="{{ benchmark_path }}"

# Define the prefix of the name of the temporary CSV file where data will be stored

prefix="{{ prefix }}"

####################################
#         Preparation step         #
####################################

# Define the name of temporary CSV file

filename="${prefix}_tmp.csv"

echo -e "\nCompiling data for benchmarking in ${benchmark_path}/${filename}."

# Create the directory where the file will be created, if needed

mkdir -p ${benchmark_path}

# If the file doesn't already exist, create it with a header as first line

header="Profile;Cluster;Jobscale;Partition;Cores;MB/CPU;Walltime;Job ID;Job Name;Scaling Function;Scale Index;Submit Date;Eligible Date;Start Date;End Date;Nodes;Nodes List"

if [ ! -f "${benchmark_path}/${filename}" ]; then
    echo -e "\nFile ${filename} does not exist in ${benchmark_path}, a new one will be created."
    echo ${header} >> ${benchmark_path}/${filename}
fi

echo -e "\nFormat:"
echo -e "${header}"

# Format SLURM dates to be (almost) readable through Excel

export SLURM_TIME_FORMAT="%Y-%m-%d %H:%M:%S"

####################################
#       Start of benchmarking      #
####################################

# Get the benchmarking values through the use of the squeue command, see https://slurm.schedmd.com/squeue.html for more information.
# xargs is used here just to remove leading and trailing whitespaces (see https://linuxhint.com/trim_string_bash/ for reference)

part=$(\squeue --Format=Partition --noheader --job=${SLURM_JOB_ID} | xargs)
cpus=$(\squeue --Format=MaxCPUs --noheader --job=${SLURM_JOB_ID} | xargs)
submit=$(\squeue --Format=SubmitTime --noheader --job=${SLURM_JOB_ID} | xargs)
eligible=$(\squeue --Format=EligibleTime --noheader --job=${SLURM_JOB_ID} | xargs)
start=$(\squeue --Format=StartTime --noheader --job=${SLURM_JOB_ID} | xargs)

# Get the current date (to calculate time used by the job)

end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Store everything into a variable

infos="{{ profile }};{{ cluster_name }};{{ jobscale_label }};${part};${cpus};{{ job_mem_per_cpu }};{{ job_walltime }};${SLURM_JOB_ID};${SLURM_JOB_NAME};{{ scaling_function }};{{ scale_index }};${submit};${eligible};${start};${end_time};${SLURM_NNODES};${SLURM_NODELIST}"

echo -e "\nContent:"
echo -e "${infos}"

# Add line to file

echo ${infos} >> ${benchmark_path}/${filename}
